{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38453743",
   "metadata": {},
   "source": [
    "# Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cfb28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer  # Built-in dataset: breast cancer classification\n",
    "from sklearn.model_selection import train_test_split  # To split data into training and testing\n",
    "from sklearn.linear_model import LogisticRegression   # ML model: Logistic Regression (linear classifier)\n",
    "from sklearn.tree import DecisionTreeClassifier       # ML model: Decision Tree (non-linear classifier)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # To evaluate model performance\n",
    "import math   # For mathematical operations (not directly needed yet)\n",
    "\n",
    "# For visualization (we may use it later to plot data)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Ignore warnings to keep the output clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6d763",
   "metadata": {},
   "source": [
    "# Data Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a422038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the built-in Breast Cancer dataset from sklearn.\n",
    "# It contains information about breast tumor cells (numerical features)\n",
    "# and the target (malignant = cancerous, benign = non-cancerous).\n",
    "data_loader = load_breast_cancer(as_frame=True)  # 'as_frame=True' gives us a pandas DataFrame\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is stored in a dictionary-like object with several keys.\n",
    "data_loader.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad001c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target is what we want to predict: cancerous or not.\n",
    "data_loader[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3285ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each dataset also comes with a description to explain it.\n",
    "print(data_loader[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e191d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview dataset\n",
    "data_loader[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'frame' combines features + target into one DataFrame for easier handling.\n",
    "data = data_loader.frame\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bd897",
   "metadata": {},
   "source": [
    "# EDA (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many samples we have for each target class\n",
    "# (0 = malignant, 1 = benign) from metadata\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the target labels easier to understand (replace 0/1 with words)\n",
    "target_meaning = {\n",
    "    0: \"malignant\",\n",
    "    1: \"benign\",\n",
    "}\n",
    "\n",
    "# Show class distribution as a bar chart\n",
    "data.target.replace(target_meaning).value_counts().plot(kind=\"bar\", rot=0, title=\"class count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c95ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics (mean, std, min, max, quartiles) for each feature\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation of each feature with the target\n",
    "# (closer to 1 or -1 -> stronger relationship)\n",
    "data_loader[\"frame\"].corr().apply(abs).loc[\"target\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3487f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of a single feature\n",
    "# \"worst concave points\" is one of the most correlated feature to target\n",
    "data[[\"worst concave points\"]].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of \"worst concave points\" between malignant and benign tumors\n",
    "sns.histplot(\n",
    "    data=data,\n",
    "    x=\"worst concave points\",\n",
    "    hue=\"target\",\n",
    "    bins=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47db13",
   "metadata": {},
   "source": [
    "Notes:  \n",
    "\n",
    "- Class balance: always check how many samples per class. Imbalanced classes can bias the model.  \n",
    "- Describe(): quick way to understand the scale and spread of features.  \n",
    "- Correlation with target: helps identify which features are most useful for prediction.  \n",
    "- Visualizations: plotting features (like worst concave points) by target shows if they separate classes well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ac9a4",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which features (columns) to use for training\n",
    "# For now we only use one feature: \"worst concave points\"\n",
    "# Later, we could try using ALL features: data.columns[:-1]\n",
    "features = ['worst concave points']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column in the DataFrame is our target (0 = malignant, 1 = benign)\n",
    "target = data.columns[-1]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ab1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into inputs (X) and output/labels (y)\n",
    "X = data[features]   # Features\n",
    "y = data[target]     # Target\n",
    "display(X)           # Show selected features\n",
    "display(y)           # Show target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1152d4",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# - 80% for training (used to fit the model)\n",
    "# - 20% for testing (used to check model performance on unseen data)\n",
    "# random_state=42 ensures reproducibility (you get the same split every time)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)\n",
    "\n",
    "# [Optional] Preview train set (features only)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda44d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Preview test set (features only)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Preview train set (target only)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f316f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Preview test set (target only)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf363512",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression is a simple linear classifier.\n",
    "# It tries to separate malignant vs benign using a straight line (or curve in higher dimensions).\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)          # Train the model using training data\n",
    "y_pred_lr = lr.predict(X_test)    # Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9194928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree is a non-linear model.\n",
    "# It splits the data into branches based on feature values (like asking yes/no questions).\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)          # Train the model using training data\n",
    "y_pred_dt = dt.predict(X_test)    # Make predictions on test dataN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee2753",
   "metadata": {},
   "source": [
    "Note:  \n",
    "\n",
    "- Both models are trained using the same training set but may perform differently.  \n",
    "- Logistic Regression = good baseline, simple, interpretable.  \n",
    "- Decision Tree = flexible, can capture more complex patterns, but may overfit.  \n",
    "- Predictions (y_pred_lr, y_pred_dt) are what the models think the test samples should be classified as.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d782c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3fa114",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d38136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Logistic Regression\n",
    "# Rows = actual labels, Columns = predicted labels\n",
    "# Top-left = correctly predicted malignant\n",
    "# Bottom-right = correctly predicted benign\n",
    "confusion_matrix(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Decision Tree\n",
    "confusion_matrix(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8ff68",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0607a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for Logistic Regression\n",
    "# Shows Precision, Recall, F1-score, and Accuracy\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for Decision Tree\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104856df",
   "metadata": {},
   "source": [
    "Note:  \n",
    "\n",
    "- Precision: Of all samples predicted as positive, how many were correct?  \n",
    "- Recall: Of all actual positives, how many did we find?  \n",
    "- F1-score: Balance between Precision and Recall.  \n",
    "- Accuracy: Overall percentage of correct predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45394965",
   "metadata": {},
   "source": [
    "# Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_concave_points_test = .03 #.11 #.1105 # .11 # .1125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained Decision Tree to predict its class\n",
    "# Note: we pass the value inside [[ ]] because the model expects a 2D array\n",
    "test_pred = dt.predict([[worst_concave_points_test]])\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba852841",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numeric prediction (0 or 1) into a human-readable label\n",
    "target_meaning[test_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb30613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trained Decision Tree\n",
    "plt.figure(figsize=(12*2, 6*2))\n",
    "plot_tree(\n",
    "    dt, \n",
    "    feature_names=features,                        # show the feature name(s)\n",
    "    class_names=list(target_meaning.values()),     # convert dict_values → list\n",
    "    filled=True, \n",
    "    rounded=True\n",
    ")\n",
    "plt.savefig(\"tree.jpg\", dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74c23c",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- Input must follow the same structure as training features (even if it’s only one feature, it must be passed as a 2D array).\n",
    "- The model output is 0 or 1, but mapping it back with target_meaning makes it understandable (\"malignant\" or \"benign\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888278f",
   "metadata": {},
   "source": [
    "## Manual Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8abc98f",
   "metadata": {},
   "source": [
    "1. **Linear function `f(x)`**  \n",
    "\n",
    "   `f(x) = w * x + b`, where:  \n",
    "\n",
    "   * `w` = coefficient from `lr.coef_`\n",
    "   * `b` = intercept from `lr.intercept_`\n",
    "   * Input `x` = `worst_concave_points_test`\n",
    "\n",
    "   This gives you a **raw score** (sometimes called logit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c97716",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lr.coef_, lr.intercept_)\n",
    "\n",
    "# f(x)\n",
    "f_x = lambda x: lr.coef_[0][0]*x + lr.intercept_[0] \n",
    "\n",
    "f_x(worst_concave_points_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5788c",
   "metadata": {},
   "source": [
    "2. **Sigmoid function `g(f(x))`**   \n",
    "   \n",
    "   `g(z) = 1 / (1 + exp(-z))`\n",
    "\n",
    "   * Converts the raw score into a probability between **0 and 1**.\n",
    "   * Example: If `f(x) = -2`, then `g(-2) ≈ 0.12` → low probability of benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g(z)\n",
    "sigmoid_fn = lambda z: 1 / (1 + math.exp(-z))\n",
    "\n",
    "# g(f(x))\n",
    "sigmoid_fn(f_x(worst_concave_points_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabd2ce",
   "metadata": {},
   "source": [
    "3. **Threshold classifier `h(g(f(x)))`**\n",
    "   \n",
    "   `h(p) = 0 if p < 0.5 else 1`\n",
    "\n",
    "   * If probability ≥ 0.5 → **class 1**\n",
    "   * If probability < 0.5 → **class 0**\n",
    "\n",
    "   That’s what your `classifier()` function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h(threshold, p)\n",
    "classifier = lambda threshold, p: 0 if p < threshold else 1\n",
    "\n",
    "# h(g(f(x)))\n",
    "given_threshold = .5\n",
    "classifier(sigmoid_fn(f_x(worst_concave_points_test)), given_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e4fb5",
   "metadata": {},
   "source": [
    "4. **Final mapping**\n",
    "\n",
    "   * You then map class `0` or `1` into **meaningful labels** using `target_meaning`.\n",
    "   * Example:\n",
    "\n",
    "     * `0 → Malignant`\n",
    "     * `1 → Benign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_meaning[\n",
    "    classifier(sigmoid_fn(f_x(worst_concave_points_test)), given_threshold)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b870f55",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "1. Multiply inputs by weights (linear formula).\n",
    "2. Pass result through **sigmoid** to squash into [0,1].\n",
    "3. Compare with **threshold (0.5)** to decide the class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom-himatika-its",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
